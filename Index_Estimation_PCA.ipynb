{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries required to estimate the index returns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spd_matrix as spd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Read in the training dataset provided by Optiver\n",
    "all_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4p/rtytcsp11j70tn7dmwys7lrm0000gn/T/ipykernel_25778/3657013184.py:12: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  weekly_ts_returns = weekly_ts_prices.pct_change(1)\n"
     ]
    }
   ],
   "source": [
    "## This is an attempt to estimate the index time series by performing PCA on the stock data\n",
    "## It used the weekly index to estimate the covariance matrix - this ensures we remove market noise\n",
    "## The factor loadings then seem to work as expected and can be thought of as index weights per stock\n",
    "## Clearly the assumption here is that the index weights remain stable throughout the dataset\n",
    "## This assumption is not true, so these weights can be thought of as average index weights over the period\n",
    "\n",
    "# For each week, calculate the stock returns and estimate the covariance matrix - use this covariance matrix in the PCA \n",
    "# to then estimate factor loadings of the first factor (likely the market factor) to each of the stocks\n",
    "end_of_day_data = all_data[all_data['seconds_in_bucket'] == 540]\n",
    "end_of_week_data = end_of_day_data[end_of_day_data['date_id'] % 5 == 0]\n",
    "weekly_ts_prices = end_of_week_data.pivot(index='date_id', columns='stock_id', values = 'wap')\n",
    "weekly_ts_returns = weekly_ts_prices.pct_change(1)\n",
    "weekly_ts_returns = weekly_ts_returns.iloc[1:]\n",
    "\n",
    "# Once we have the returns we need to z-score the returns per stock to ensure the PCA does not \"reward\" more volatile ones\n",
    "weekly_ts_returns_zcore = (weekly_ts_returns - weekly_ts_returns.mean()) / weekly_ts_returns.std(ddof=0)\n",
    "\n",
    "# Some of the stocks have missing data for some dates/weeks - we will use the pd.corr() function\n",
    "# This function ignores the missing data and estimates the pairwise correlation which is helpful\n",
    "cov_matrix = weekly_ts_returns.cov()\n",
    "\n",
    "# Given the corr() function estimates pairwise correlation ignoring missing data, it might not be PD\n",
    "# Use the function below to get the nearest PD matrix to the original one before any PCA is done\n",
    "cov_matrix_spd = spd.nearestPD(cov_matrix)\n",
    "\n",
    "# Perform the PCA on this correlation matrix to get the factor loadings of the first factor\n",
    "# This first factor should be the market factor and then we can normalise loadings to get index weights\n",
    "num_assets = len(weekly_ts_returns.columns)\n",
    "pca = PCA(n_components=num_assets, svd_solver='full')\n",
    "pca.fit(cov_matrix_spd)\n",
    "factor_loadings_cov = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "factor_loadings_mkt_cov = factor_loadings_cov[:, 0]\n",
    "factor_loadings_mkt_cov = factor_loadings_mkt_cov / sum(factor_loadings_mkt_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4p/rtytcsp11j70tn7dmwys7lrm0000gn/T/ipykernel_25778/1856129383.py:15: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  date_ts_returns = date_ts_prices.pct_change(1)\n",
      "/var/folders/4p/rtytcsp11j70tn7dmwys7lrm0000gn/T/ipykernel_25778/1856129383.py:15: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  date_ts_returns = date_ts_prices.pct_change(1)\n",
      "/var/folders/4p/rtytcsp11j70tn7dmwys7lrm0000gn/T/ipykernel_25778/1856129383.py:15: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  date_ts_returns = date_ts_prices.pct_change(1)\n",
      "/var/folders/4p/rtytcsp11j70tn7dmwys7lrm0000gn/T/ipykernel_25778/1856129383.py:15: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  date_ts_returns = date_ts_prices.pct_change(1)\n"
     ]
    }
   ],
   "source": [
    "## The covariance approach using weekly data provided the best result in terms of index weights (all positive)\n",
    "## We will now use these weights to estimate the index returns for each timestep in the original dataset\n",
    "\n",
    "# Initialise empty variable to assign index returns to later\n",
    "max_dates = int(max(all_data['date_id']) + 1)\n",
    "timesteps_per_day = int(max(all_data['seconds_in_bucket']) / 10)\n",
    "idx_returns = np.empty((max_dates * timesteps_per_day, 3,))\n",
    "idx_returns[:, 1] = list(range(10, max(all_data['seconds_in_bucket']) + 1, 10)) * max_dates\n",
    "\n",
    "# Loop through each date to calculate index returns - we do this due to missing stock data, etc.\n",
    "for date_id in range(max(all_data['date_id']) + 1):\n",
    "\n",
    "    date_data = all_data[all_data['date_id'] == date_id]\n",
    "    date_ts_prices = date_data.pivot(index='time_id', columns='stock_id', values='wap')\n",
    "    date_ts_returns = date_ts_prices.pct_change(1)\n",
    "    date_ts_returns = date_ts_returns.iloc[1:]\n",
    "\n",
    "    # In case of any missing data, remove all data for that stock\n",
    "    date_ts_returns.dropna(axis=1,how='any',inplace=True)\n",
    "    valid_stock_ids = sorted(date_ts_returns.columns)\n",
    "\n",
    "    # Only get the factor loadings for the stocks with data in this timestep\n",
    "    valid_factor_loadings = factor_loadings_mkt_cov[valid_stock_ids]\n",
    "\n",
    "    # Normalise the factor loadings for the stocks with data\n",
    "    norm_factor_loadings = valid_factor_loadings / sum(valid_factor_loadings)\n",
    "\n",
    "    # Calculate the index returns based on stock returns and factor loadings\n",
    "    date_idx_contr = date_ts_returns * norm_factor_loadings.T\n",
    "    date_idx_returns = date_idx_contr.sum(axis=1)\n",
    "\n",
    "    # Assign output to the index return variable \n",
    "    idx_returns[timesteps_per_day * date_id : timesteps_per_day * (date_id + 1), 0] = date_id\n",
    "    idx_returns[timesteps_per_day * date_id : timesteps_per_day * (date_id + 1), 2] = date_idx_returns\n",
    "\n",
    "idx_rets_df = pd.DataFrame(idx_returns)\n",
    "idx_rets_df.rename(columns={0: 'date_id', 1: 'seconds_in_bucket', 2: 'idx_rets'},inplace=True)\n",
    "\n",
    "idx_rets_df.to_parquet('idx_rets.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The cells below this are ones which were used to test other ways of estimating the index weights\n",
    "## They did not work as well as the covariance approach using weekly stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is an attempt to estimate the index time series by performing PCA on the stock data\n",
    "## It used the weekly index to estimate the correlation matrix - this ensures we remove market noise\n",
    "## The factor loadings then seem to work as expected and can be thought of as index weights per stock\n",
    "## Clearly the assumption here is that the index weights remain stable throughout the dataset\n",
    "## This assumption is not true, so these weights can be thought of as average index weights over the period\n",
    "\n",
    "# For each week, calculate the stock returns and estimate the correlation matrix - use this correlation matrix in the PCA \n",
    "# to then estimate factor loadings of the first factor (likely the market factor) to each of the stocks\n",
    "end_of_day_data = all_data[all_data['seconds_in_bucket'] == max(all_data['seconds_in_bucket'])]\n",
    "end_of_week_data = end_of_day_data[end_of_day_data['date_id'] % 5 == 0]\n",
    "weekly_ts_prices = end_of_week_data.pivot(index='date_id', columns='stock_id', values = 'wap')\n",
    "weekly_ts_returns = weekly_ts_prices.pct_change(1)\n",
    "weekly_ts_returns = weekly_ts_returns.iloc[1:]\n",
    "\n",
    "# Some of the stocks have missing data for some dates/weeks - we will use the pd.corr() function\n",
    "# This function ignores the missing data and estimates the pairwise correlation which is helpful\n",
    "corr_matrix = weekly_ts_returns.corr()\n",
    "\n",
    "# Given the corr() function estimates pairwise correlation ignoring missing data, it might not be PD\n",
    "# Use the function below to get the nearest PD matrix to the original one before any PCA is done\n",
    "corr_matrix_spd = spd.nearestPD(corr_matrix)\n",
    "\n",
    "# Perform the PCA on this correlation matrix to get the factor loadings of the first factor\n",
    "# This first factor should be the market factor and then we can normalise loadings to get index weights\n",
    "num_assets = len(weekly_ts_returns.columns)\n",
    "pca = PCA(n_components=num_assets, svd_solver='full')\n",
    "pca.fit(corr_matrix_spd)\n",
    "factor_loadings_corr = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "factor_loadings_mkt_corr = factor_loadings_corr[:, 0]\n",
    "factor_loadings_mkt_corr = factor_loadings_mkt_corr / sum(factor_loadings_mkt_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This was an attempt to estimate the index time series by performing PCA on the stock data\n",
    "## It used the 10s tick data to estimate the correlation matrix - this tick data will have a lot of noise\n",
    "## The factor loadings did not work as expected due to this noise\n",
    "\n",
    "# For each date, calculate the stock returns and estimate the correlation matrix - use this correlation matrix in the PCA \n",
    "# to then estimate factor loadings of the first factor (likely the market factor) to each of the stocks\n",
    "max_dates = max(all_data['date_id']) + 1\n",
    "max_assets = max(all_data['stock_id']) + 1\n",
    "daily_loadings_mkt = np.empty((max_dates, max_assets,))\n",
    "daily_loadings_mkt[:] = np.nan\n",
    "\n",
    "for date_id in range(max(all_data['date_id']) + 1):\n",
    "    date_data = all_data[all_data['date_id'] == date_id]\n",
    "    # Pivot the dataframe to create a wap time series for all the stocks\n",
    "    date_ts_prices = date_data.pivot(index='time_id', columns='stock_id', values = 'wap')\n",
    "    # Check for any empty columns and remove them\n",
    "    date_ts_prices.dropna(how='all', axis=1, inplace=True)   \n",
    "    stock_ids = sorted(date_ts_prices.columns.unique())\n",
    "    num_assets = len(date_ts_prices.columns)\n",
    "    date_ts_returns = date_ts_prices.pct_change(1)\n",
    "    date_ts_returns = date_ts_returns.iloc[1:]\n",
    "    corr_matrix = date_ts_returns.corr()\n",
    "    pca = PCA(n_components=num_assets, svd_solver='full')\n",
    "    pca.fit(corr_matrix)\n",
    "    factor_loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "    factor_loadings_mkt = factor_loadings[:, 0]\n",
    "    factor_loadings_mkt = factor_loadings_mkt / sum(factor_loadings_mkt)\n",
    "    daily_loadings_mkt[date_id, stock_ids] = factor_loadings_mkt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
